from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import train_test_split
from sklearn import metrics

# Sample dataset
text_data = [
    "Berkshire retains and reinvests earnings when doing so delivers at least proportional increases in per share market value over time.",
    "It uses debt sparingly and sells equity only when it receives as much in value as it gives.",
    "Buffett penetrates accounting conventions, especially those that obscure real economic earnings."
]

# Corresponding labels (1 for positive, 0 for negative)
labels = [1, 1, 1]

# Split dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(text_data, labels, test_size=0.25, random_state=42)

# Create a pipeline with TfidfVectorizer and Naive Bayes classifier
model = make_pipeline(TfidfVectorizer(), MultinomialNB())

# Train the model
model.fit(X_train, y_train)

# Predict on test data
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = metrics.accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy:.2f}")

# Function to classify new text
def classify_text(text):
    prediction = model.predict([text])
    return "Positive" if prediction[0] == 1 else "Negative"

# Example usage
new_text = "Berkshire retains and reinvests earnings."
print(f"Classification: {classify_text(new_text)}")

